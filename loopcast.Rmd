---
title: "Loop Cast"
output: html_document
author: Jordan Wente
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(imputeTS)
library(rnoaa)
library(dygraphs)
library(lubridate)
library(magrittr)
library(xts)
library(timeDate)
```

```{r data load,include=FALSE,show=FALSE}

data<-read_csv("loop2.csv")

summary(data)
#data$recs<-seq(1,length(data$`Virtual.zzXcel_Total#Block Demand Real Power#kW`))
#data[data$recs %in% errs,]


data[is.na(data[,2]),2]<-data[is.na(data[,2]),3]

data$Timestamp %<>% mdy_hm() 

#errs<-data[is.na(data$Timestamp),4]


names(data)<-c("time","block","real")   #all units in kW

data$block %<>% na_interpolation()  #linear interpolation for the remaining datapoints that don't print

#tz(data$time)<-"America/Chicago"  Not necessary 
#apply.hourly <- function(x, FUN,...) {
#  ep <- endpoints(x, 'hours')
#  period.apply(x, ep, FUN, ...)
#}

```


First, I will need to create exogenous variables like holidays etc..


```{r time series}

ys<- data$time %>% year() %>% as.factor %>% levels() %>% as.numeric()
hols<- ys %>%  holidayNYSE %>% as.Date              #Using the NYSE as a hoilday database. 

data$hour<-hour(data$time)
data$date<-as.Date(data$time)
data$block<-data$block*.25    #converting to kWh


#convert to hourly time series

data2<- data %>% group_by(hour,date) %>% summarise_at("block",sum) %>% mutate(time=paste0(date," ",hour,":","00")) %>% mutate_at("time",ymd_hm) %>% arrange(time) 

data2$weekday<-data2$time %>% isWeekday() %>% as.numeric
data2$holiday<-0
data2$holiday[as.Date(data2$time) %in% hols]<-1  # These seems to work pretty well. 

```


```{r weather data, include=FALSE}
#Run the "functions": script to get the hourly weather data function, data is downloaded from: http://mesonet.agron.iastate.edu/request/download.phtml?network=MN_ASOS
#Made this other function because it was too heavy and I just needed something simpler. 


tz_data<-"America%2FChicago" #TZ - get it in the TZ you want. 

td<-today()
#this function is simple and downloads data for a single year. Downloads the data to a temp file. 

msp.w<-getMSPw(station="MSP",2013,01,01,year2=year(td),month2=month(td),day2=day(td),tz_data = tz_data)

msp.w$valid %<>% as.character()
msp.w2<-msp.w[is.na(msp.w$tmpf)==F,]
      

```

```{r write and merge weather file, include=FALSE}


msp.w2$valid %<>% as.character() %>% ymd_hm()

msp.w2$date<-as.Date(msp.w2$valid)
msp.w2$hour<-hour(msp.w2$valid)


d2<-left_join(data2,msp.w2)

d2$tmpf %<>% na_interpolation()
d2$dwpf %<>% na_interpolation()
d2$sknt %<>% na_interpolation()
d2$p01i %<>% as.numeric() %>% na_interpolation()

```



```{r timeseries creation}
d2$ts<-xts(d2$block,order.by = d2$time,frequency = 24)
d2$ts %>% dygraph() %>% dyOptions(useDataTimezone = TRUE)
d2$week<- week(d2$time) %>% as.factor()
d2$month<-month(d2$time) %>% as.factor()
d2$year<-year(d2$time) %>% as.factor()



peaks<- d2 %>% group_by(month,year) %>% summarize_at("block",max) 
names(peaks)<-c("month","year","peak")

d2<-left_join(d2,peaks)
d2$bln<-d2$block/d2$peak

d2$bts<- as.xts(d2$bln,order.by=d2$time,frequency=24)

mods<- c("beta_regression","neural_network","arimax","ets") %>% enframe() 

mods %>% group_by(value) %>% mutate(data=nest(d2))

```


